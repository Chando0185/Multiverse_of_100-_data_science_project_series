{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi5Hkq2u3h8F"
      },
      "outputs": [],
      "source": [
        "!pip install langchain langchain-community langchain-core langchain-groq faiss-cpu sentence-transformers docling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4laVtCm93h-m"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import warnings\n",
        "from docling.document_converter import DocumentConverter\n",
        "from pathlib import Path\n",
        "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "import faiss\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain import hub\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_groq import ChatGroq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X8u38auD3iBj"
      },
      "outputs": [],
      "source": [
        "# Document conversion\n",
        "def load_and_convert_document(file_path):\n",
        "    converter = DocumentConverter()\n",
        "    result = converter.convert(file_path)\n",
        "    return result.document.export_to_markdown()\n",
        "\n",
        "source = \"/content/amazon-10-q-q3-2024.pdf\"\n",
        "markdown_content = load_and_convert_document(source)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "duYWViPx3vXl"
      },
      "outputs": [],
      "source": [
        "# Splitting markdown content into chunks\n",
        "def get_markdown_splits(markdown_content):\n",
        "    headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n",
        "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on, strip_headers=False)\n",
        "    return markdown_splitter.split_text(markdown_content)\n",
        "chunks = get_markdown_splits(markdown_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eg0iYheq3xj7"
      },
      "outputs": [],
      "source": [
        "# Embedding and vector store setup\n",
        "def setup_vector_store(chunks):\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    single_vector = embeddings.embed_query(\"this is some text data\")\n",
        "    index = faiss.IndexFlatL2(len(single_vector))\n",
        "    vector_store = FAISS(\n",
        "        embedding_function=embeddings,\n",
        "        index=index,\n",
        "        docstore=InMemoryDocstore(),\n",
        "        index_to_docstore_id={}\n",
        "    )\n",
        "    vector_store.add_documents(documents=chunks)\n",
        "    return vector_store\n",
        "\n",
        "vector_store = setup_vector_store(chunks)\n",
        "\n",
        "# Setup retriever\n",
        "retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={'k': 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66kEOzdD3zhV"
      },
      "outputs": [],
      "source": [
        "# Formatting documents for RAG\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join([doc.page_content for doc in docs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PuERiLC31SG"
      },
      "outputs": [],
      "source": [
        "# Setting up the RAG chain\n",
        "def create_rag_chain(retriever):\n",
        "    prompt = \"\"\"\n",
        "        You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question.\n",
        "        If you don't know the answer, just say that you don't know.\n",
        "        Answer in bullet points. Make sure your answer is relevant to the question and it is answered from the context only.\n",
        "        Question: {question}\n",
        "        Context: {context}\n",
        "        Answer:\n",
        "    \"\"\"\n",
        "    model = ChatGroq(model_name=\"llama3-8b-8192\", api_key = \"\")  # ✅ Choose a Groq-supported model\n",
        "    prompt_template = ChatPromptTemplate.from_template(prompt)\n",
        "    return (\n",
        "        {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "        | prompt_template\n",
        "        | model\n",
        "        | StrOutputParser()\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcyhw7f6_72z"
      },
      "outputs": [],
      "source": [
        "# Create RAG chain\n",
        "rag_chain = create_rag_chain(retriever)\n",
        "\n",
        "questions = [\n",
        "    \"What was Amazon’s total revenue in Q3 2024?\",\n",
        "    \"How does the revenue in Q3 2024 compare to Q3 2023?\",\n",
        "    \"What was the net income for Q3 2024, and how does it compare year over year?\",\n",
        "    \"What were the earnings per share (basic and diluted) in Q3 2024?\",\n",
        "    \"How much did Amazon earn from product vs. service sales?\",\n",
        "    \"What were the main operating expense categories and their values in Q3 2024?\",\n",
        "    \"What was Amazon’s operating income in Q3 2024?\",\n",
        "    ]\n",
        "\n",
        "\n",
        "for question in questions:\n",
        "      print(f\"Question: {question}\")\n",
        "      for chunk in rag_chain.stream(question):\n",
        "          print(chunk, end=\"\", flush=True)\n",
        "      print(\"\\n\" + \"-\" * 50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        },
        "id": "sv6X3pM-39SM",
        "outputId": "e367314b-a69b-4b1c-f565-78ab4cfa6593"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-8-3080301700.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# Load document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msource\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/amazon-10-q-q3-2024.pdf\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmarkdown_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_and_convert_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_markdown_splits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarkdown_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3-546158266.py\u001b[0m in \u001b[0;36mload_and_convert_document\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_and_convert_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mconverter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDocumentConverter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_to_markdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_validate_call.py\u001b[0m in \u001b[0;36mwrapper_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;31m# We need to manually update this because `partial` object has no `__name__` and `__qualname__`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_validate_call.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_validators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pydantic_validator__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydantic_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgsKwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__return_pydantic_validator__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__return_pydantic_validator__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling/document_converter.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mpage_range\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpage_range\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         )\n\u001b[0;32m--> 235\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mvalidate_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mConfigDict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling/document_converter.py\u001b[0m in \u001b[0;36mconvert_all\u001b[0;34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0mhad_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mconv_res\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconv_res_iter\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0mhad_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             if raises_on_error and conv_res.status not in {\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling/document_converter.py\u001b[0m in \u001b[0;36m_convert\u001b[0;34m(self, conv_input, raises_on_error)\u001b[0m\n\u001b[1;32m    291\u001b[0m             \u001b[0;31m# Note: PDF backends are not thread-safe, thread pool usage was disabled.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             for item in map(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_document\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraises_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraises_on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0minput_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling/document_converter.py\u001b[0m in \u001b[0;36m_process_document\u001b[0;34m(self, in_doc, raises_on_error)\u001b[0m\n\u001b[1;32m    337\u001b[0m         )\n\u001b[1;32m    338\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m             \u001b[0mconv_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraises_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraises_on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0merror_message\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"File format not allowed: {in_doc.file}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling/document_converter.py\u001b[0m in \u001b[0;36m_execute_pipeline\u001b[0;34m(self, in_doc, raises_on_error)\u001b[0m\n\u001b[1;32m    360\u001b[0m             \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_pipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_doc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                 \u001b[0mconv_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraises_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraises_on_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mraises_on_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling/pipeline/base_pipeline.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, in_doc, raises_on_error)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;31m# These steps are building and assembling the structure of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;31m# output DoclingDocument.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m                 \u001b[0mconv_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mconv_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assemble_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_res\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m                 \u001b[0;31m# From this stage, all operations should rely only on conv_res.output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling/pipeline/base_pipeline.py\u001b[0m in \u001b[0;36m_build_document\u001b[0;34m(self, conv_res)\u001b[0m\n\u001b[1;32m    158\u001b[0m                     \u001b[0mpipeline_pages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_on_pages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_pages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpipeline_pages\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Must exhaust!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                         \u001b[0;31m# Cleanup cached images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeep_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling/pipeline/base_pipeline.py\u001b[0m in \u001b[0;36m_apply_on_pages\u001b[0;34m(self, conv_res, page_batch)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mpage_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconv_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpage_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_res\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConversionResult\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mConversionResult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling/models/page_assemble_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, conv_res, page_batch)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconv_res\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConversionResult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpage_batch\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPage\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     ) -> Iterable[Page]:\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpage_batch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_valid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling/models/table_structure_model.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, conv_res, page_batch)\u001b[0m\n\u001b[1;32m    248\u001b[0m                             \u001b[0mpage_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tokens\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m                             tf_output = self.tf_predictor.multi_table_predict(\n\u001b[0m\u001b[1;32m    251\u001b[0m                                 \u001b[0mpage_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtbl_box\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_matching\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_cell_matching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling_ibm_models/tableformer/data_management/tf_predictor.py\u001b[0m in \u001b[0;36mmulti_table_predict\u001b[0;34m(self, iocr_page, table_bboxes, do_matching, correct_overlapping_cells, sort_row_col_indexes)\u001b[0m\n\u001b[1;32m    492\u001b[0m             \u001b[0;31m# Predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdo_matching\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m                 tf_responses, predict_details = self.predict(\n\u001b[0m\u001b[1;32m    495\u001b[0m                     \u001b[0miocr_page\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                     \u001b[0mtable_bbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling_ibm_models/tableformer/data_management/tf_predictor.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, iocr_page, table_bbox, table_image, scale_factor, eval_res_preds, correct_overlapping_cells)\u001b[0m\n\u001b[1;32m    750\u001b[0m                 \u001b[0mpred_tag_seq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_res_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tag_seq\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"predict\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"bbox\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m                 pred_tag_seq, outputs_class, outputs_coord = self._model.predict(\n\u001b[0m\u001b[1;32m    753\u001b[0m                     \u001b[0mimage_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeam_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling_ibm_models/tableformer/models/table04_rs/tablemodel04_rs.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, imgs, max_steps, k, return_attention)\u001b[0m\n\u001b[1;32m    183\u001b[0m             )\n\u001b[1;32m    184\u001b[0m             \u001b[0mAggProfiler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"model_tag_transformer_decoder\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             decoded, cache = self._tag_transformer._decoder(\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0mdecoded_embedding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0mencoder_out\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/docling_ibm_models/tableformer/models/table04_rs/transformer_rs.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, tgt, memory, cache, memory_mask, tgt_key_padding_mask, memory_key_padding_mask)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# cache\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mtag_cache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mtag_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_copy_to_script_wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__iadd__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mSelf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Main execution logic\n",
        "if __name__ == \"__main__\":\n",
        "    # Load document\n",
        "    source = \"/content/amazon-10-q-q3-2024.pdf\"\n",
        "    markdown_content = load_and_convert_document(source)\n",
        "    chunks = get_markdown_splits(markdown_content)\n",
        "\n",
        "    # Create vector store\n",
        "    vector_store = setup_vector_store(chunks)\n",
        "\n",
        "    # Setup retriever\n",
        "    retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={'k': 3})\n",
        "\n",
        "    # Create RAG chain\n",
        "    rag_chain = create_rag_chain(retriever)\n",
        "\n",
        "    # Questions for retrieval\n",
        "    # Questions for retrieval (Amazon-specific)\n",
        "    questions = [\n",
        "    # Financial Performance\n",
        "    \"What was Amazon’s total revenue in Q3 2024?\",\n",
        "    \"How does the revenue in Q3 2024 compare to Q3 2023?\",\n",
        "    \"What was the net income for Q3 2024, and how does it compare year over year?\",\n",
        "    \"What were the earnings per share (basic and diluted) in Q3 2024?\",\n",
        "    \"How much did Amazon earn from product vs. service sales?\",\n",
        "    \"What were the main operating expense categories and their values in Q3 2024?\",\n",
        "    \"What was Amazon’s operating income in Q3 2024?\",\n",
        "    ]\n",
        "\n",
        "\n",
        "\n",
        "    # Answer questions\n",
        "    for question in questions:\n",
        "        print(f\"Question: {question}\")\n",
        "        for chunk in rag_chain.stream(question):\n",
        "            print(chunk, end=\"\", flush=True)\n",
        "        print(\"\\n\" + \"-\" * 50 + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4lNzTKh739VV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tnIOIgTA4lQp"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Global variable to store vector store and RAG chain after file upload\n",
        "vector_store = None\n",
        "rag_chain = None\n",
        "\n",
        "def upload_and_process(file):\n",
        "    global vector_store, rag_chain\n",
        "    file_path = file.name\n",
        "    markdown_content = load_and_convert_document(file_path)\n",
        "    chunks = get_markdown_splits(markdown_content)\n",
        "    vector_store = setup_vector_store(chunks)\n",
        "    retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={'k': 3})\n",
        "    rag_chain = create_rag_chain(retriever)\n",
        "    return \"✅ Document processed and RAG chain created. You can now ask questions.\"\n",
        "\n",
        "def ask_question(question):\n",
        "    if rag_chain is None:\n",
        "        return \"❌ Please upload and process a document first.\"\n",
        "    response = \"\"\n",
        "    for chunk in rag_chain.stream(question):\n",
        "        response += chunk\n",
        "    return response\n",
        "\n",
        "# Launch Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 📊 Amazon 10-Q RAG-Based QA System using Groq + FAISS\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            file_input = gr.File(label=\"📁 Upload Amazon 10-Q PDF\", file_types=[\".pdf\"])\n",
        "            upload_btn = gr.Button(\"🔄 Upload & Process\")\n",
        "            upload_output = gr.Textbox(label=\"Processing Status\", lines=2)\n",
        "\n",
        "        with gr.Column():\n",
        "            question_input = gr.Textbox(label=\"❓ Ask a Question\", placeholder=\"e.g. What was Amazon’s total revenue in Q3 2024?\")\n",
        "            ask_btn = gr.Button(\"🔍 Get Answer\")\n",
        "            answer_output = gr.Textbox(label=\"📢 Answer\", lines=10)\n",
        "\n",
        "    upload_btn.click(fn=upload_and_process, inputs=[file_input], outputs=[upload_output])\n",
        "    ask_btn.click(fn=ask_question, inputs=[question_input], outputs=[answer_output])\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef5MuwpF4qWo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i92Jag6S4qaO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swc0pM6P323s"
      },
      "outputs": [],
      "source": [
        "# Main execution logic\n",
        "if __name__ == \"__main__\":\n",
        "    # Load document\n",
        "    source = \"/content/amazon-10-q-q3-2024.pdf\"\n",
        "    markdown_content = load_and_convert_document(source)\n",
        "    chunks = get_markdown_splits(markdown_content)\n",
        "\n",
        "    # Create vector store\n",
        "    vector_store = setup_vector_store(chunks)\n",
        "\n",
        "    # Setup retriever\n",
        "    retriever = vector_store.as_retriever(search_type=\"mmr\", search_kwargs={'k': 3})\n",
        "\n",
        "    # Create RAG chain\n",
        "    rag_chain = create_rag_chain(retriever)\n",
        "\n",
        "    # Questions for retrieval\n",
        "    # Questions for retrieval (Amazon-specific)\n",
        "    questions = [\n",
        "    # Financial Performance\n",
        "    \"What was Amazon’s total revenue in Q3 2024?\",\n",
        "    \"How does the revenue in Q3 2024 compare to Q3 2023?\",\n",
        "    \"What was the net income for Q3 2024, and how does it compare year over year?\",\n",
        "    \"What were the earnings per share (basic and diluted) in Q3 2024?\",\n",
        "    \"How much did Amazon earn from product vs. service sales?\",\n",
        "    \"What were the main operating expense categories and their values in Q3 2024?\",\n",
        "    \"What was Amazon’s operating income in Q3 2024?\",\n",
        "\n",
        "    # Segment Analysis\n",
        "    \"What was the revenue and operating income for Amazon Web Services (AWS) in Q3 2024?\",\n",
        "    \"How did the North America and International segments perform in terms of revenue and profit?\",\n",
        "    \"Which segment contributed the most to Amazon’s operating income?\",\n",
        "\n",
        "    # Cash Flow & Capital Expenditures\n",
        "    \"How much cash did Amazon generate from operating activities?\",\n",
        "    \"What were the major uses of cash in investing and financing activities?\",\n",
        "    \"What were Amazon’s capital expenditures in Q3 2024?\",\n",
        "\n",
        "    # Debt and Liabilities\n",
        "    \"What is Amazon’s total long-term debt as of September 30, 2024?\",\n",
        "    \"What are the upcoming debt maturities and interest rates for Amazon's outstanding bonds?\",\n",
        "\n",
        "    # Stock & Shareholder Equity\n",
        "    \"What were the changes in stockholders’ equity this quarter?\",\n",
        "    \"Did Amazon repurchase any stock in Q3 2024?\",\n",
        "\n",
        "    # Other Financial Indicators\n",
        "    \"What are the values of accounts receivable, inventories, and marketable securities as of September 30, 2024?\",\n",
        "    \"What were Amazon’s total assets and liabilities?\",\n",
        "\n",
        "    # Legal and Regulatory\n",
        "    \"What major legal proceedings or lawsuits was Amazon involved in during Q3 2024?\",\n",
        "    \"What was the outcome of the Kove IO patent case?\",\n",
        "    \"Are there any significant antitrust or consumer protection investigations ongoing?\",\n",
        "\n",
        "    # Taxation and Accounting\n",
        "    \"What is Amazon’s effective tax rate for Q3 2024?\",\n",
        "    \"What discrete tax items impacted Amazon’s tax expense?\",\n",
        "    \"Are there any significant tax disputes or contingencies noted?\",\n",
        "\n",
        "    # Revenue Breakdown\n",
        "    \"What was the revenue breakdown by business line (Online stores, AWS, advertising, etc.)?\",\n",
        "    \"How did subscription services and advertising revenue perform compared to last year?\"\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "    # Answer questions\n",
        "    for question in questions:\n",
        "        print(f\"Question: {question}\")\n",
        "        for chunk in rag_chain.stream(question):\n",
        "            print(chunk, end=\"\", flush=True)\n",
        "        print(\"\\n\" + \"-\" * 50 + \"\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
